{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "df = pd.read_csv('./events.csv')\n",
    "\n",
    "\n",
    "events = df['event']\n",
    "dates = df['date'].astype(int)\n",
    "\n",
    "# Preprocess the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(events)\n",
    "total_events = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f9b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "events = df['event']\n",
    "dates = df['date'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114efd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for i, event in enumerate(events):\n",
    "    token_list = tokenizer.texts_to_sequences([event])[0]\n",
    "    sequences.append((token_list, dates[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a416ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_event_length = max([len(seq[0]) for seq in sequences])\n",
    "padded_sequences = []\n",
    "for seq, date in sequences:\n",
    "    padded_event = pad_sequences([seq], maxlen=max_event_length, padding='pre')[0]\n",
    "    padded_sequences.append((padded_event, date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b257992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictors and labels\n",
    "X = np.array([seq for seq, _ in padded_sequences])\n",
    "y = np.array([date for _, date in padded_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09dfdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_events, 100, input_length=max_event_length))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=5000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f42a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./event-predictor-2880epoch.h5')\n",
    "import pickle\n",
    "\n",
    "# Assuming tokenizer is your Tokenizer object\n",
    "# Save the tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d3bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load the tokenizer\n",
    "with open('./tokenizer.pickle', 'rb') as handle:\n",
    "    loaded_tokenizer = pickle.load(handle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a9f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_events, 100, input_length=max_event_length))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "model.load_weights('./event-predictor-2880epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e5e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Function to generate event based on seed text and date\n",
    "def generate_event(seed_text, event_date, model, max_event_length, tokenizer):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    padded_event = pad_sequences([token_list], maxlen=max_event_length, padding='pre')\n",
    "    predicted_date = model.predict(padded_event)[0][0]\n",
    "    return predicted_date\n",
    "\n",
    "# Example usage\n",
    "seed_event = \"The egyptian revulation\"\n",
    "predicted_date = generate_event(seed_event, seed_date, model, max_event_length, tokenizer)\n",
    "print(\"Predicted date for {}: {}\".format(seed_event, int(predicted_date)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c92f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "seed_event = \"the arabian revulation\"\n",
    "seed_date = 2050\n",
    "predicted_date = generate_event(seed_event, seed_date, model, max_event_length, tokenizer)\n",
    "print(\"Predicted date for {}: {}\".format(seed_event, int(predicted_date)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb17db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_event = \"the world war III\" \n",
    "seed_date = 2050\n",
    "predicted_date = generate_event(seed_event, seed_date, model, max_event_length, tokenizer)\n",
    "print(\"Predicted date for {}: {}\".format(seed_event, int(predicted_date)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2629c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'we Are at year 1742 and accourding to the cyclye of the dates 1811 will be 2095'\n",
    "'we Are at year 1742 and accourding to the cyclye of the dates 1450 will be 2029-2030'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f389f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
